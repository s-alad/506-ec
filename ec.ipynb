{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd5dd1f7-82b8-4cd4-aa3d-0b15d61daf5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - conda-forge\n",
      " - nvidia\n",
      " - pytorch\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "    current version: 24.7.1\n",
      "    latest version: 24.11.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c conda-forge conda\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%conda install pandas numpy seaborn matplotlib xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31d830a5-e1d7-4aea-b9dd-2237d26e220f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, PowerTransformer\n",
    "from datetime import datetime\n",
    "from os.path import exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfa9cf65-8ba3-48ee-b1df-cbbc543e3d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n"
     ]
    }
   ],
   "source": [
    "class FeatureProcessor:\n",
    "    @staticmethod\n",
    "    def calculate_distance(df):\n",
    "        a = np.sin((np.radians(df['merch_lat']) - np.radians(df['lat']))/2)**2 + np.cos(np.radians(df['lat']))*np.cos(np.radians(df['merch_lat']))*np.sin((np.radians(df['merch_long']) - np.radians(df['long']))/2)**2\n",
    "        distance = 6371 * (2 * np.arctan2(np.sqrt(a), np.sqrt(1-a)))\n",
    "        df['distance_to_merchant'] = distance\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def add_time_features(df):\n",
    "        df['trans_datetime'] = pd.to_datetime(df['trans_date'] + ' ' + df['trans_time'])\n",
    "        df['hour'] = df['trans_datetime'].dt.hour\n",
    "        df['day_of_week'] = df['trans_datetime'].dt.dayofweek\n",
    "        df['is_weekend'] = df['day_of_week'].isin([5,6]).astype(int)\n",
    "        df['is_night'] = df['hour'].between(23,6).astype(int)\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_amt_per_capita(df):\n",
    "        df['amt_per_capita'] = df['amt'] / (df['city_pop']+1)\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_age(df):\n",
    "        df['age'] = (pd.to_datetime('today') - pd.to_datetime(df['dob'])).dt.days // 365\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def categorize_age(df):\n",
    "        df['age_group'] = pd.cut(df['age'], bins=[0,20,40,60,80,100], labels=['0-20','21-40','41-60','61-80','81-100'])\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def user_avg_amt(df_train, df_test):\n",
    "        df_train_75 = df_train.sample(frac=0.75, random_state=0)\n",
    "        user_avg = df_train_75.groupby('cc_num')['amt'].mean().reset_index()\n",
    "        user_avg.columns = ['cc_num', 'avg_transaction_amt']\n",
    "        df_train = df_train.merge(user_avg, on='cc_num', how='left')\n",
    "        df_test = df_test.merge(user_avg, on='cc_num', how='left')\n",
    "        overall_avg = df_train_75['amt'].mean()\n",
    "        df_train['avg_transaction_amt'].fillna(overall_avg, inplace=True)\n",
    "        df_test['avg_transaction_amt'].fillna(overall_avg, inplace=True)\n",
    "        return df_train, df_test\n",
    "\n",
    "    @staticmethod\n",
    "    def user_std_amt(df_train, df_test):\n",
    "        df_train_75 = df_train.sample(frac=0.75, random_state=0)\n",
    "        user_std = df_train_75.groupby('cc_num')['amt'].std().reset_index()\n",
    "        user_std.columns = ['cc_num','std_dev_transaction_amt']\n",
    "        df_train = df_train.merge(user_std, on='cc_num', how='left')\n",
    "        df_test = df_test.merge(user_std, on='cc_num', how='left')\n",
    "        overall_std = df_train_75['amt'].std()\n",
    "        df_train['std_dev_transaction_amt'].fillna(overall_std, inplace=True)\n",
    "        df_test['std_dev_transaction_amt'].fillna(overall_std, inplace=True)\n",
    "        return df_train, df_test\n",
    "\n",
    "    @staticmethod\n",
    "    def merchant_avg_amt(df_train, df_test):\n",
    "        df_train_75 = df_train.sample(frac=0.75, random_state=0)\n",
    "        merch_avg = df_train_75.groupby('merchant')['amt'].mean().reset_index()\n",
    "        merch_avg.columns = ['merchant','avg_amount_per_merchant']\n",
    "        df_train = df_train.merge(merch_avg, on='merchant', how='left')\n",
    "        df_test = df_test.merge(merch_avg, on='merchant', how='left')\n",
    "        overall_avg = df_train_75['amt'].mean()\n",
    "        df_train['avg_amount_per_merchant'].fillna(overall_avg, inplace=True)\n",
    "        df_test['avg_amount_per_merchant'].fillna(overall_avg, inplace=True)\n",
    "        return df_train, df_test\n",
    "\n",
    "    @staticmethod\n",
    "    def merchant_std_amt(df_train, df_test):\n",
    "        df_train_75 = df_train.sample(frac=0.75, random_state=0)\n",
    "        merch_std = df_train_75.groupby('merchant')['amt'].std().reset_index()\n",
    "        merch_std.columns = ['merchant','std_dev_amount_per_merchant']\n",
    "        df_train = df_train.merge(merch_std, on='merchant', how='left')\n",
    "        df_test = df_test.merge(merch_std, on='merchant', how='left')\n",
    "        overall_std = df_train_75['amt'].std()\n",
    "        df_train['std_dev_amount_per_merchant'].fillna(overall_std, inplace=True)\n",
    "        df_test['std_dev_amount_per_merchant'].fillna(overall_std, inplace=True)\n",
    "        return df_train, df_test\n",
    "\n",
    "    @staticmethod\n",
    "    def category_avg_amt(df_train, df_test):\n",
    "        df_train_75 = df_train.sample(frac=0.75, random_state=0)\n",
    "        cat_avg = df_train_75.groupby('category')['amt'].mean().reset_index()\n",
    "        cat_avg.columns = ['category','avg_amount_per_category']\n",
    "        df_train = df_train.merge(cat_avg, on='category', how='left')\n",
    "        df_test = df_test.merge(cat_avg, on='category', how='left')\n",
    "        overall_avg = df_train_75['amt'].mean()\n",
    "        df_train['avg_amount_per_category'].fillna(overall_avg, inplace=True)\n",
    "        df_test['avg_amount_per_category'].fillna(overall_avg, inplace=True)\n",
    "        return df_train, df_test\n",
    "\n",
    "    @staticmethod\n",
    "    def category_std_amt(df_train, df_test):\n",
    "        df_train_75 = df_train.sample(frac=0.75, random_state=0)\n",
    "        cat_std = df_train_75.groupby('category')['amt'].std().reset_index()\n",
    "        cat_std.columns = ['category','std_dev_amount_per_category']\n",
    "        df_train = df_train.merge(cat_std, on='category', how='left')\n",
    "        df_test = df_test.merge(cat_std, on='category', how='left')\n",
    "        overall_std = df_train_75['amt'].std()\n",
    "        df_train['std_dev_amount_per_category'].fillna(overall_std, inplace=True)\n",
    "        df_test['std_dev_amount_per_category'].fillna(overall_std, inplace=True)\n",
    "        return df_train, df_test\n",
    "\n",
    "    @staticmethod\n",
    "    def job_avg_amt(df_train, df_test):\n",
    "        df_train_75 = df_train.sample(frac=0.75, random_state=0)\n",
    "        job_avg = df_train_75.groupby('job')['amt'].mean().reset_index()\n",
    "        job_avg.columns = ['job','avg_amount_per_job']\n",
    "        df_train = df_train.merge(job_avg, on='job', how='left')\n",
    "        df_test = df_test.merge(job_avg, on='job', how='left')\n",
    "        overall_avg = df_train_75['amt'].mean()\n",
    "        df_train['avg_amount_per_job'].fillna(overall_avg, inplace=True)\n",
    "        df_test['avg_amount_per_job'].fillna(overall_avg, inplace=True)\n",
    "        return df_train, df_test\n",
    "\n",
    "    @staticmethod\n",
    "    def job_std_amt(df_train, df_test):\n",
    "        df_train_75 = df_train.sample(frac=0.75, random_state=0)\n",
    "        job_std = df_train_75.groupby('job')['amt'].std().reset_index()\n",
    "        job_std.columns = ['job','std_dev_amount_per_job']\n",
    "        df_train = df_train.merge(job_std, on='job', how='left')\n",
    "        df_test = df_test.merge(job_std, on='job', how='left')\n",
    "        overall_std = df_train_75['amt'].std()\n",
    "        df_train['std_dev_amount_per_job'].fillna(overall_std, inplace=True)\n",
    "        df_test['std_dev_amount_per_job'].fillna(overall_std, inplace=True)\n",
    "        return df_train, df_test\n",
    "\n",
    "    @staticmethod\n",
    "    def user_median_amt(df_train, df_test):\n",
    "        df_train_75 = df_train.sample(frac=0.75, random_state=0)\n",
    "        user_median = df_train_75.groupby('cc_num')['amt'].median().reset_index()\n",
    "        user_median.columns = ['cc_num','user_median_transaction_amt']\n",
    "        df_train = df_train.merge(user_median, on='cc_num', how='left')\n",
    "        df_test = df_test.merge(user_median, on='cc_num', how='left')\n",
    "        overall_med = df_train_75['amt'].median()\n",
    "        df_train['user_median_transaction_amt'].fillna(overall_med, inplace=True)\n",
    "        df_test['user_median_transaction_amt'].fillna(overall_med, inplace=True)\n",
    "        return df_train, df_test\n",
    "\n",
    "    @staticmethod\n",
    "    def merchant_median_amt(df_train, df_test):\n",
    "        df_train_75 = df_train.sample(frac=0.75, random_state=0)\n",
    "        merch_median = df_train_75.groupby('merchant')['amt'].median().reset_index()\n",
    "        merch_median.columns = ['merchant','median_amount_per_merchant']\n",
    "        df_train = df_train.merge(merch_median, on='merchant', how='left')\n",
    "        df_test = df_test.merge(merch_median, on='merchant', how='left')\n",
    "        overall_med = df_train_75['amt'].median()\n",
    "        df_train['median_amount_per_merchant'].fillna(overall_med, inplace=True)\n",
    "        df_test['median_amount_per_merchant'].fillna(overall_med, inplace=True)\n",
    "        return df_train, df_test\n",
    "\n",
    "    @classmethod\n",
    "    def apply_all_features(cls, train, test):\n",
    "        train = cls.calculate_distance(train)\n",
    "        test = cls.calculate_distance(test)\n",
    "\n",
    "        train = cls.add_time_features(train)\n",
    "        test = cls.add_time_features(test)\n",
    "\n",
    "        train = cls.compute_amt_per_capita(train)\n",
    "        test = cls.compute_amt_per_capita(test)\n",
    "\n",
    "        train = cls.compute_age(train)\n",
    "        test = cls.compute_age(test)\n",
    "\n",
    "        train = cls.categorize_age(train)\n",
    "        test = cls.categorize_age(test)\n",
    "\n",
    "        train, test = cls.user_avg_amt(train, test)\n",
    "        train, test = cls.user_std_amt(train, test)\n",
    "        train, test = cls.merchant_avg_amt(train, test)\n",
    "        train, test = cls.merchant_std_amt(train, test)\n",
    "        train, test = cls.category_avg_amt(train, test)\n",
    "        train, test = cls.category_std_amt(train, test)\n",
    "        train, test = cls.job_avg_amt(train, test)\n",
    "        train, test = cls.job_std_amt(train, test)\n",
    "        train, test = cls.user_median_amt(train, test)\n",
    "        train, test = cls.merchant_median_amt(train, test)\n",
    "\n",
    "        return train, test\n",
    "\n",
    "print(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40a5c14b-9a51-4c93-ab57-9791c98f4df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.csv shape: (370703, 24)\n",
      "test.csv shape: (92676, 23)\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "# Load Data\n",
    "########################################\n",
    "\n",
    "train_set = pd.read_csv(\"train.csv\")\n",
    "test_set = pd.read_csv(\"test.csv\")\n",
    "\n",
    "print(\"train.csv shape:\", train_set.shape)\n",
    "print(\"test.csv shape:\", test_set.shape)\n",
    "\n",
    "train_set, test_set = FeatureProcessor.apply_all_features(train_set, test_set)\n",
    "\n",
    "unnecessary_cols = ['trans_date','trans_time','trans_datetime','first','last','street','city','zip','dob','cc_num']\n",
    "train_set.drop(unnecessary_cols, axis=1, inplace=True, errors='ignore')\n",
    "test_set.drop(unnecessary_cols, axis=1, inplace=True, errors='ignore')\n",
    "\n",
    "print(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfebe6c1-1137-4819-ab11-9e0f137b415e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n"
     ]
    }
   ],
   "source": [
    "cat_cols = ['trans_num','category','gender','state','job','merchant','age_group']\n",
    "for col in cat_cols:\n",
    "    train_set[col] = train_set[col].astype(str)\n",
    "    test_set[col] = test_set[col].astype(str)\n",
    "    le = LabelEncoder()\n",
    "    combined_values = list(train_set[col]) + list(test_set[col])\n",
    "    le.fit(combined_values)\n",
    "    train_set[col] = le.transform(train_set[col])\n",
    "    test_set[col] = le.transform(test_set[col])\n",
    "\n",
    "print(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9316df15-870e-4946-a418-75ff2299fefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n"
     ]
    }
   ],
   "source": [
    "X_full = train_set.drop(['id','is_fraud'], axis=1)\n",
    "Y_full = train_set['is_fraud']\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_full, Y_full, test_size=0.25, random_state=0)\n",
    "\n",
    "print(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2dd544ed-4e41-4b2f-9215-edc0a43c07b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.9770529110563246\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(n_estimators=200, max_depth=10, random_state=0, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_model.fit(X_train, Y_train)\n",
    "Y_pred_xgb = xgb_model.predict(X_val)\n",
    "score = f1_score(Y_val, Y_pred_xgb)\n",
    "\n",
    "print(f\"score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e694efe-350e-473d-923e-f12be8f87d30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<>\n"
     ]
    }
   ],
   "source": [
    "X_test_final = test_set.drop(['id'], axis=1)\n",
    "test_predictions = xgb_model.predict(X_test_final)\n",
    "\n",
    "submission = pd.DataFrame({'id': test_set['id'], 'is_fraud': test_predictions})\n",
    "submission.to_csv('final.csv', index=False)\n",
    "\n",
    "print(\"<>\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
